
模型评估与基准测试系统准测试系统。
开发标准化测试集，覆盖不同应用场景和任务类型实现自动化测试流程，
支持批量模型评估添加评估结里可视化和比较功自实现评估历史记录和趋势分析添加模型推荐功能，
根据应用需求推荐最合适的模型评估框架设计(可扩展的测试类型和指标)。
测试集构建(多样化的任务和难度级别)。
自动化测试实现(批处理、并行执行)。
评估指标计算(准确率、一致性、创造性等)。
结果可视化(雷达图、对比图表等)。
模型推荐算法(基于评估结果和应用需求)。
历史数据管理和趋势分析完整的评估框架实现，
支持至少5种评估维度标准化测试集，
包含至少 100 个测试样例自动化测试 API，
支持批量评估评估报告生成功能，
包含详细分析和可视化用户友好的自定义评估任务创建界面。
详细的 API文档和使用指南系统可扩展性良好，
支持新评估维度的添加单元测试和集成测试覆盖主要功能

项目背景: 
为了帮助用户选择最适合其应用场景的模型，
需要开发一个模型评估与基
设计并实现模型评估框架，
支持多维度能力评估(理解力、创造力、推理能力）。
开发自定义评估任务创建功能，
允许用户定义特定领域的测试


系统架构：
前端（React） ↔ 后端（FastAPI） ↔ 数据库（MongoDB）
               ↕
            Celery异步任务
               ↕
         模型推理API（多个LLM）

主要模块：
- 评估框架核心
- 测试集管理
- 自动化测试引擎
- 结果分析与可视化
- 模型推荐系统
- 用户自定义任务接口
